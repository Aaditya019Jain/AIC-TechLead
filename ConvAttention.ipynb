{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# CIFAR-10 preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
        "\n",
        "# Load CIFAR-10 test dataset\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n",
        "\n",
        "class CNNWithoutAttention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNWithoutAttention, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(128 * 8 * 8, 512)\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = x.view(-1, 128 * 8 * 8)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the model and move it to GPU\n",
        "model = CNNWithoutAttention().to(device)\n",
        "\n",
        "# Train the model\n",
        "def train_model(model, criterion, optimizer, num_epochs=5):\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            if i % 200 == 199:  # Print every 200 mini-batches\n",
        "                print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 200))\n",
        "                running_loss = 0.0\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "train_model(model, criterion, optimizer, num_epochs=10)\n",
        "\n",
        "# Define a function to test the model\n",
        "def test_model(model, testloader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data[0].to(device), data[1].to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the 10000 test images: %.2f %%' % (100 * correct / total))\n",
        "\n",
        "# Test the model\n",
        "test_model(model, testloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQdYyi4g0-09",
        "outputId": "660605e0-ab9a-496d-8665-884c7c6e1332"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda:0\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "[1,   200] loss: 1.587\n",
            "[1,   400] loss: 1.222\n",
            "[1,   600] loss: 1.073\n",
            "[2,   200] loss: 0.864\n",
            "[2,   400] loss: 0.837\n",
            "[2,   600] loss: 0.796\n",
            "[3,   200] loss: 0.606\n",
            "[3,   400] loss: 0.602\n",
            "[3,   600] loss: 0.615\n",
            "[4,   200] loss: 0.405\n",
            "[4,   400] loss: 0.429\n",
            "[4,   600] loss: 0.435\n",
            "[5,   200] loss: 0.225\n",
            "[5,   400] loss: 0.233\n",
            "[5,   600] loss: 0.286\n",
            "[6,   200] loss: 0.121\n",
            "[6,   400] loss: 0.127\n",
            "[6,   600] loss: 0.156\n",
            "[7,   200] loss: 0.068\n",
            "[7,   400] loss: 0.074\n",
            "[7,   600] loss: 0.103\n",
            "[8,   200] loss: 0.048\n",
            "[8,   400] loss: 0.058\n",
            "[8,   600] loss: 0.078\n",
            "[9,   200] loss: 0.046\n",
            "[9,   400] loss: 0.060\n",
            "[9,   600] loss: 0.086\n",
            "[10,   200] loss: 0.031\n",
            "[10,   400] loss: 0.050\n",
            "[10,   600] loss: 0.067\n",
            "Accuracy of the network on the 10000 test images: 72.75 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# CIFAR-10 preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
        "\n",
        "# Load CIFAR-10 test dataset\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(SelfAttention, self).__init__()\n",
        "\n",
        "        self.query_conv = nn.Conv2d(in_channels, in_channels // 8, kernel_size=1)\n",
        "        self.key_conv = nn.Conv2d(in_channels, in_channels // 8, kernel_size=1)\n",
        "        self.value_conv = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n",
        "        self.gamma = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, channels, height, width = x.size()\n",
        "\n",
        "        query = self.query_conv(x).view(batch_size, -1, width * height).permute(0, 2, 1)\n",
        "        key = self.key_conv(x).view(batch_size, -1, width * height)\n",
        "\n",
        "        energy = torch.bmm(query, key)\n",
        "        attention = F.softmax(energy, dim=-1)\n",
        "\n",
        "        value = self.value_conv(x).view(batch_size, -1, width * height)\n",
        "\n",
        "        out = torch.bmm(value, attention.permute(0, 2, 1))\n",
        "        out = out.view(batch_size, channels, height, width)\n",
        "\n",
        "        out = self.gamma * out + x\n",
        "        return out\n",
        "\n",
        "class CNNWithAttention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNWithAttention, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
        "        self.attention1 = SelfAttention(64)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.attention2 = SelfAttention(128)\n",
        "        self.fc1 = nn.Linear(128 * 8 * 8, 512)\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.attention1(x)\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.attention2(x)\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = x.view(-1, 128 * 8 * 8)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the model and move it to GPU\n",
        "model = CNNWithAttention().to(device)\n",
        "\n",
        "# Train the model\n",
        "def train_model(model, criterion, optimizer, num_epochs=5):\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            if i % 200 == 199:  # Print every 200 mini-batches\n",
        "                print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 200))\n",
        "                running_loss = 0.0\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "train_model(model, criterion, optimizer, num_epochs=10)\n",
        "\n",
        "# Define a function to test the model\n",
        "def test_model(model, testloader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data[0].to(device), data[1].to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the 10000 test images: %.2f %%' % (100 * correct / total))\n",
        "\n",
        "# Test the model\n",
        "test_model(model, testloader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P87brDQWx_-3",
        "outputId": "abde7b21-c046-4b7c-91b9-42081131e666"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda:0\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "[1,   200] loss: 1.657\n",
            "[1,   400] loss: 1.293\n",
            "[1,   600] loss: 1.103\n",
            "[2,   200] loss: 0.868\n",
            "[2,   400] loss: 0.832\n",
            "[2,   600] loss: 0.795\n",
            "[3,   200] loss: 0.618\n",
            "[3,   400] loss: 0.596\n",
            "[3,   600] loss: 0.598\n",
            "[4,   200] loss: 0.386\n",
            "[4,   400] loss: 0.405\n",
            "[4,   600] loss: 0.423\n",
            "[5,   200] loss: 0.198\n",
            "[5,   400] loss: 0.219\n",
            "[5,   600] loss: 0.242\n",
            "[6,   200] loss: 0.104\n",
            "[6,   400] loss: 0.103\n",
            "[6,   600] loss: 0.123\n",
            "[7,   200] loss: 0.057\n",
            "[7,   400] loss: 0.067\n",
            "[7,   600] loss: 0.069\n",
            "[8,   200] loss: 0.058\n",
            "[8,   400] loss: 0.061\n",
            "[8,   600] loss: 0.073\n",
            "[9,   200] loss: 0.043\n",
            "[9,   400] loss: 0.059\n",
            "[9,   600] loss: 0.064\n",
            "[10,   200] loss: 0.046\n",
            "[10,   400] loss: 0.051\n",
            "[10,   600] loss: 0.079\n",
            "Accuracy of the network on the 10000 test images: 73.85 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# CIFAR-10 preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
        "\n",
        "\n",
        "testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(SelfAttention, self).__init__()\n",
        "\n",
        "        self.query_conv = nn.Conv2d(in_channels, in_channels // 8, kernel_size=1)\n",
        "        self.key_conv = nn.Conv2d(in_channels, in_channels // 8, kernel_size=1)\n",
        "        self.value_conv = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n",
        "        self.gamma = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, channels, height, width = x.size()\n",
        "\n",
        "        query = self.query_conv(x).view(batch_size, -1, width * height).permute(0, 2, 1)\n",
        "        key = self.key_conv(x).view(batch_size, -1, width * height)\n",
        "\n",
        "        energy = torch.bmm(query, key)\n",
        "        attention = F.softmax(energy, dim=-1)\n",
        "\n",
        "        value = self.value_conv(x).view(batch_size, -1, width * height)\n",
        "\n",
        "        out = torch.bmm(value, attention.permute(0, 2, 1))\n",
        "        out = out.view(batch_size, channels, height, width)\n",
        "\n",
        "        out = self.gamma * out + x\n",
        "        return out\n",
        "\n",
        "class CNNWithAttention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNWithAttention, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
        "        self.attention1 = SelfAttention(64)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.attention2 = SelfAttention(128)\n",
        "        self.fc1 = nn.Linear(128 * 8 * 8, 512)\n",
        "        self.fc2 = nn.Linear(512, 100)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.attention1(x)\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.attention2(x)\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = x.view(-1, 128 * 8 * 8)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the model and move it to GPU\n",
        "model = CNNWithAttention().to(device)\n",
        "\n",
        "# Train the model\n",
        "def train_model(model, criterion, optimizer, num_epochs=5):\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            if i % 200 == 199:  # Print every 200 mini-batches\n",
        "                print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 200))\n",
        "                running_loss = 0.0\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "train_model(model, criterion, optimizer, num_epochs=10)\n",
        "\n",
        "# Define a function to test the model\n",
        "def test_model(model, testloader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data[0].to(device), data[1].to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the 10000 test images: %.2f %%' % (100 * correct / total))\n",
        "\n",
        "# Test the model\n",
        "test_model(model, testloader)\n"
      ],
      "metadata": {
        "id": "Kht0rB2QdcQI",
        "outputId": "495ed92a-b0e0-4192-c3dd-fc21af5e044d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda:0\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169001437/169001437 [00:03<00:00, 49124398.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-100-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "[1,   200] loss: 3.997\n",
            "[1,   400] loss: 3.348\n",
            "[1,   600] loss: 2.996\n",
            "[2,   200] loss: 2.453\n",
            "[2,   400] loss: 2.354\n",
            "[2,   600] loss: 2.300\n",
            "[3,   200] loss: 1.793\n",
            "[3,   400] loss: 1.797\n",
            "[3,   600] loss: 1.813\n",
            "[4,   200] loss: 1.195\n",
            "[4,   400] loss: 1.258\n",
            "[4,   600] loss: 1.337\n",
            "[5,   200] loss: 0.669\n",
            "[5,   400] loss: 0.740\n",
            "[5,   600] loss: 0.805\n",
            "[6,   200] loss: 0.300\n",
            "[6,   400] loss: 0.320\n",
            "[6,   600] loss: 0.397\n",
            "[7,   200] loss: 0.163\n",
            "[7,   400] loss: 0.169\n",
            "[7,   600] loss: 0.208\n",
            "[8,   200] loss: 0.119\n",
            "[8,   400] loss: 0.120\n",
            "[8,   600] loss: 0.149\n",
            "[9,   200] loss: 0.119\n",
            "[9,   400] loss: 0.129\n",
            "[9,   600] loss: 0.163\n",
            "[10,   200] loss: 0.108\n",
            "[10,   400] loss: 0.133\n",
            "[10,   600] loss: 0.153\n",
            "Accuracy of the network on the 10000 test images: 40.74 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import resnet18\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define SelfAttention module\n",
        "# class SelfAttention(nn.Module):\n",
        "#     def __init__(self, in_channels):\n",
        "#         super(SelfAttention, self).__init__()\n",
        "\n",
        "#         self.query_conv = nn.Conv2d(in_channels, in_channels // 8, kernel_size=1)\n",
        "#         self.key_conv = nn.Conv2d(in_channels, in_channels // 8, kernel_size=1)\n",
        "#         self.value_conv = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n",
        "#         self.gamma = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         batch_size, channels, height, width = x.size()\n",
        "\n",
        "#         query = self.query_conv(x).view(batch_size, -1, width * height).permute(0, 2, 1)\n",
        "#         key = self.key_conv(x).view(batch_size, -1, width * height)\n",
        "\n",
        "#         energy = torch.bmm(query, key)\n",
        "#         attention = F.softmax(energy, dim=-1)\n",
        "\n",
        "#         value = self.value_conv(x).view(batch_size, -1, width * height)\n",
        "\n",
        "#         out = torch.bmm(value, attention.permute(0, 2, 1))\n",
        "#         out = out.view(batch_size, channels, height, width)\n",
        "\n",
        "#         out = self.gamma * out + x\n",
        "#         return out\n",
        "\n",
        "# Define the ResNet with Self Attention\n",
        "class ResNetWithoutAttention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ResNetWithoutAttention, self).__init__()\n",
        "        self.resnet = resnet18(pretrained=True)\n",
        "        # self.attention = SelfAttention(in_channels=512)  # ResNet18 output channels\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.resnet.conv1(x)\n",
        "        x = self.resnet.bn1(x)\n",
        "        x = self.resnet.relu(x)\n",
        "        x = self.resnet.maxpool(x)\n",
        "        x = self.resnet.layer1(x)\n",
        "        x = self.resnet.layer2(x)\n",
        "        x = self.resnet.layer3(x)\n",
        "        x = self.resnet.layer4(x)\n",
        "        x = self.resnet.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.resnet.fc(x)\n",
        "        return x\n",
        "\n",
        "# CIFAR-10 dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n",
        "\n",
        "# Initialize the model\n",
        "model = ResNetWithoutAttention()\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(5):  # Loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 200 == 199:  # Print every 200 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 200))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "# Test the model\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mT12-pkoFd79",
        "outputId": "b5dbcbaa-8a0b-4c38-ec91-d7e758424bec"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 46119356.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 164MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   200] loss: 1.480\n",
            "[1,   400] loss: 0.431\n",
            "[1,   600] loss: 0.337\n",
            "[2,   200] loss: 0.181\n",
            "[2,   400] loss: 0.167\n",
            "[2,   600] loss: 0.168\n",
            "[3,   200] loss: 0.092\n",
            "[3,   400] loss: 0.095\n",
            "[3,   600] loss: 0.090\n",
            "[4,   200] loss: 0.052\n",
            "[4,   400] loss: 0.049\n",
            "[4,   600] loss: 0.048\n",
            "[5,   200] loss: 0.028\n",
            "[5,   400] loss: 0.028\n",
            "[5,   600] loss: 0.031\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 93 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import resnet18\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define SelfAttention module\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(SelfAttention, self).__init__()\n",
        "\n",
        "        self.query_conv = nn.Conv2d(in_channels, in_channels // 8, kernel_size=1)\n",
        "        self.key_conv = nn.Conv2d(in_channels, in_channels // 8, kernel_size=1)\n",
        "        self.value_conv = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n",
        "        self.gamma = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, channels, height, width = x.size()\n",
        "\n",
        "        query = self.query_conv(x).view(batch_size, -1, width * height).permute(0, 2, 1)\n",
        "        key = self.key_conv(x).view(batch_size, -1, width * height)\n",
        "\n",
        "        energy = torch.bmm(query, key)\n",
        "        attention = F.softmax(energy, dim=-1)\n",
        "\n",
        "        value = self.value_conv(x).view(batch_size, -1, width * height)\n",
        "\n",
        "        out = torch.bmm(value, attention.permute(0, 2, 1))\n",
        "        out = out.view(batch_size, channels, height, width)\n",
        "\n",
        "        out = self.gamma * out + x\n",
        "        return out\n",
        "\n",
        "# Define the ResNet with Self Attention\n",
        "class ResNetWithAttention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ResNetWithAttention, self).__init__()\n",
        "        self.resnet = resnet18(pretrained=True)\n",
        "        self.attention = SelfAttention(in_channels=512)  # ResNet18 output channels\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.resnet.conv1(x)\n",
        "        x = self.resnet.bn1(x)\n",
        "        x = self.resnet.relu(x)\n",
        "        x = self.resnet.maxpool(x)\n",
        "\n",
        "        x = self.resnet.layer1(x)\n",
        "        x = self.resnet.layer2(x)\n",
        "        x = self.resnet.layer3(x)\n",
        "        x = self.resnet.layer4(x)\n",
        "\n",
        "        x = self.attention(x)  # Apply self attention\n",
        "\n",
        "        x = self.resnet.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.resnet.fc(x)\n",
        "        return x\n",
        "\n",
        "# CIFAR-10 dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n",
        "\n",
        "# Initialize the model\n",
        "model = ResNetWithAttention()\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(5):  # Loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 200 == 199:  # Print every 200 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 200))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "# Test the model\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJC6hsGb7a87",
        "outputId": "8d4cc170-bfe9-49ed-bce1-6fcbd68dd567"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "[1,   200] loss: 1.484\n",
            "[1,   400] loss: 0.427\n",
            "[1,   600] loss: 0.337\n",
            "[2,   200] loss: 0.182\n",
            "[2,   400] loss: 0.167\n",
            "[2,   600] loss: 0.182\n",
            "[3,   200] loss: 0.091\n",
            "[3,   400] loss: 0.086\n",
            "[3,   600] loss: 0.084\n",
            "[4,   200] loss: 0.044\n",
            "[4,   400] loss: 0.041\n",
            "[4,   600] loss: 0.045\n",
            "[5,   200] loss: 0.026\n",
            "[5,   400] loss: 0.021\n",
            "[5,   600] loss: 0.018\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 93 %\n"
          ]
        }
      ]
    }
  ]
}